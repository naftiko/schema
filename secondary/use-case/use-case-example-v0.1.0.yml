
#-----------------------------------------------------
# These are our top 3 use cases we are focused on.
# These will be printed and available at APIDays booth
#-----------------------------------------------------

- name: AI Context
  description: |- # Description provides a summary, plus what teams are needing. 
    This use case focuses on providing Model Context Protocol (MCP) servers on top of common private, public/1st party and 3rd party APIs, as well as local SQL databases, employing a domain-driven, declarative, and governed approach to right-sizing the context windows via MCP while providing integrations for us across AI copilots and agents. 

    Teams need a reliable way to deliver MCP servers from internal and third-party APIs without having to discover and learn about each API and the technical details of integration. This use case provides the fundamentals for safely integrating existing data and systems into artificial intelligence copilots and agents.

  benefits: # Benefits used in docks, decks, and diagrams

    - Add data and tools to agents
    - Compose MCP servers
    - Aggregate & curate context

  pain: # Used to align pain with Signals targets

    - title: Copilot Leadership Mandate
      targets:
        - Cvent
    - title: MCP Leadership Mandate
      targets:
        - Ford
      targets:
        - Ford       
    - title: Unmanaged Encryption
      targets:
        - Ford    
    - title: Unmanaged Discovery
      targets:
        - Cvent
        - Ford
    - title: Unmanaged Authentication        
    - title: Unmanaged Usage
    - title: Unmanaged Cost        

  gains: # Used to align gains with Signals targets

    - title: 3rd-Pary Data in Copilot
    - title: 3rd-Party MCP Available
    - title: Manage Budget Across
    - title: Managed Risk Involved
    - title: Optimize SaaS Usage
    - title: Create More Visibility (Ford)
    - title: Create More Discovery (Ford)
    - title: Create More Reusability (Chase)  

  narratives: # These are the narratives for this use case - published to blog.

    - title: Our Partners and Customers Need an AI Copilot
      body:

        We have been extremely successful with our API-first transformation over the last decade here at Acme Corp.. Our 500+ distributed engineers are roughly 75% design-first and are producing a solid base of OpenAPI-defined HTTP APIs, with Webhooks, GraphQL, gRPC, and Kafka APIs. Then earlier this year, the boss came and said we were going all-in on AI, and we needed a copilot for our partners and eventually our customers.

        We didn't know what to do. We've spent the last six months rallying teams to produce compelling prototypes that would get us closer to something meeting our leadership's mandate for an AI copilot. Luckily, we've had a somewhat centralized API governance effort in motion for the last five years and were beginning to consider how we would also govern third-party APIs—the usage of Claude, ChatGPT, Gemini APIs, Hugging Face, Ollama, and local SLM/LLMs but also other third-party APIs delivered to any of those LLMs. This demonstrated that the problem was growing.

        Clearly we needed MCP servers. Teams published many different solutions using existing OpenAPI and AsyncAPI specifications to generate MCP servers in various programming languages. As it stands today, there isn't any notion of discovery across these MCP servers. Teams don't have any consistent or organized way of doing MCP. Everything is only used internally so far, with mixed results across the copilots and agents being deployed on top of MCP servers. Like with our federated API development and our recent investment in our API platform, we need more standardization of MCP deployment alongside SDKs, Jupyter Notebooks, and other clients.

        Nothing has made it to production—well, a handful of very safe, low-risk projects, but nothing customer-facing. The result of eight months of exploration is that we need more context to make our AI integrations work. We need the real-world context present in the third-party services we use each day available as part of our AI chats and agentic workflows. We also find that AI integrations are much more useful and relevant when they connect local SQL databases in addition to HTTP APIs, providing access to data they need—leaving us realizing we need more legacy data access as well. Right now, we are most concerned with giving teams guidance on how to consistently and dynamically generate MCP servers from existing OpenAPI and AsyncAPI artifacts—work that would benefit from guided, declarative, and composite set of capabilities that are mapped to various sources as defined by the consumers of our AI integrations.

        Once we standardize how we deliver MCP servers across teams, we need a way to make them discoverable alongside other API resources. We need to encourage more reuse and interoperability, as well as discovery and onboarding across APIs and MCP servers—taking the base of OpenAPI-defined HTTP APIs, with Webhooks, GraphQL, gRPC, and Kafka APIs, and aggregating or splitting them up depending on their shape and form as reusable source capabilities that can be assembled into use-case and domain-specific composite capabilities. We are just learning and adapting right now, trying to do as much as we can with fewer team members by leveraging open-source solutions. In these uncertain times, we are most concerned with the complexity of our operations, maximizing productivity across short-handed teams, and managing risk and cost by leveraging AI automation. We need to be able to do more with less and do not have the time to learn new processes or purchase new services—we just need help.

      targets: 

        - Ford
        - Cvent
        - Goldman Sachs
        - Chase      

# This is our second top use case
- name: API Reusability
  description: |- # Description provides a summary, plus what teams are needing.
    This use case is concerned with encouraging the discoverability and reuse of existing APIs, leveraging existing API infrastructure to quantify what API, schema, and tooling reuse looks like, and incentivizing reuse of APIs and schema across the software development lifecycle—reducing API sprawl and hardening the APIs that already exist.

    Teams need to be able to easily use existing API paths and operations as part of new integrations and automation, ensuring that paths, operations, and schema are available within IDE and copilot tooling—meeting developers where they already work. API reusability enables developers while also informing leadership regarding what API reuse looks like and where opportunities to refine exist.

  benefits: # Benefits used in docks, decks, and diagrams

    - Unlock access to legacy data
    - Right-size & unify APIs
    - Foundation for AI initiatives

  pain: # Used to align pain with Signals targets

    - title: Build on existing internal APIs
      targets:
        - Cvent
        - Chase
    - title: Reuse 3rd-party APIs already used
      targets:
        - Cvent
        - Chase
    - title: Need to leverage existing OpenAPIs
      targets:
        - Cvent   
        - Chase         
    - title: We do not understand what API reuse is
      targets:
        - Chase   
    - title: We aren't able to communicate API reuse
      targets:
        - Chase            
    - title: Need to incentivize reuse within IDEs and copilots
      targets:
        - Chase           

  gains: # Used to align gains with Signals targets

    - title: Leverage existing internal API catalog
    - title: Establish API catalog for 3rd-party APIs
    - title: Extend existing OpenAPI for MCP delivery
    - title: We are able to communicate reuse to leadership
    - title: We are able to meet developers where they work

  narratives: # These are the narratives for this use case - published to blog.

    - title: API Reuse Has Helped Stabilize Our Investment in Artificial Intellience
      body:

        A central team has done the hard work to organize all of the internal and public APIs our company produces into a central catalog that we can access via portal, API, and even Git. We are beginning the work to do the same with all of the 3rd-party APIs like Microsoft Graph, Claude, and Stripe. Now that we have all of this in motion, we want to understand and incentivize the reuse of these APIs across teams and integrations.

        Now that we have access to our internal, public, and 3rd-party APIs, we need to define what reuse means. Through mapping of the existing API landscape, we can identify the API paths, parameters, headers, schemas, and other common components being used. To do this, we need to aggregate these properties across APIs, beginning with our HTTP APIs, but then expanding from there—currently we do not have a common definition of what API reuse means.

        We have established an initial understanding of what API reuse looks like across lines of business, different domains, and teams. Now we need to find an effective way of communicating this across teams, but also, more importantly, with leadership. We have begun publishing aggregate information about API paths, parameters, headers, schemas, and other properties into our existing observability tools, providing real-time dashboards for how APIs are being reused or not across our company.

        Significant progress has been made in quantifying and communicating what API reuse is all about. Next we need to incentivize the reuse of internal, public, and 3rd-party APIs across teams. We've opted to inject common patterns needing reuse into existing developer workflows via IDE and copilot, meeting developers where they are when it comes to incentivizing reuse. Next, we'll measure the impact of these incentives as part of our overall understanding.

        API reuse began as a problem across our web and mobile applications, but has grown unmanageable as part of our cloud and SaaS integrations. As we saw this problem further exploding because of artificial intelligence, we recognized an opportunity to use AI to understand, communicate, and incentivize the reuse of data and APIs across our company. Investing in API reuse has saved us time and money in just a couple of months, and these benefits will continue to grow over time.

      targets: 

        - Cvent
        - Chase  
        - Bloomberg  

# This is our third top use case
- name: AI Orchestration
  description: |- # Description provides a summary, plus what teams are needing.
    This use case provides the data, skills, and capabilities that artificial intelligence agents used internally can use to automate and orchestrate tasks while discovering and negotiating with other agents to accomplish specific goals. This use case employs the open-source Agent-2-Agent specification to securely and confidently enable agentic activity across operations.

    As teams focus on responding to this AI moment and deploying MCP servers on top of existing APIs and other tooling, they need to begin understanding how to implement agentic automation and orchestration on top of MCP servers. Teams need structure and guidance when it comes to authentication and authorization, discovery, governance, and all the standardization required to deploy agents at scale.

  benefits: # Benefits used in docks, decks, and diagrams

    - Discover skills & capabilities
    - Internal & external agents
    - Implement A2A protocol

  pain: # Used to align pain with Signals targets

    - title: Need to do AI agents

  gains:

    - title: Get to do AI Agents

  narratives: # These are the narratives for this use case - published to blog.

    - title: Need Title
      body:

        Need narrative body.

      targets: 

        - Need Signals Targets  

#------------------------------------------------------------
# These are the rest of the use cases we have been working on.
#------------------------------------------------------------

- name: SQL Data Access
  description: |-
    This use case seeks to consistently unlock the data companies currently depend upon across multiple third-party SaaS providers and a variety of existing database connections via JDBC and ODBC to ensure AI integrations have the data they require. Data today is spread across many internal and external systems, and making it consistently available as part of AI integrations has significantly slowed the delivery of new products and features.

    Teams benefit from consistent SQL access to data sources via ODBC/JDBC interfaces, and expanding this access to third-party SaaS will help teams provide the context, resources, tooling, and data needed to deliver AI integrations across the enterprise. The capability and resulting engine deployment for this use case provides a unified, consolidated, and simplified approach to providing the data needed to power individual AI integrations within specific business domains.

  benefits:
    - Unlock SaaS data
    - JDBC / ODBC drivers
    - Federated SQL processing

  pain:

    - Limited or No Access to SaaS Data for AI Integration
    - No Access to Data Sources for AIN Integration
    - Unmanaged Usage
    - Unmanaged Spend
    - Unmanaged API Tokens
    - Unmanaged Encryption
    - Unmanaged Discovery  
    - Demand for 3rd-Party Data for Business Intelligence in Dashboards
    - Demand for 3rd-Party Data by Data Science for ML Engineering

  gains:  

    - Access to SaaS Data via SQL
    - Access to Data Sources via SQL
    - Manage Budget Across
    - Managed Risk Involved
    - Optimize SaaS Usage
    - Create More Visibility
    - Create More Discovery
    - Create More Reusability

- name: AI Model Mediation
  description: |-
    This use case focuses on managing different artificial intelligence models, providing an open-source alternative to OpenRouter that helps teams manage development across multiple public and private AI models. Model routing is primarily done using the APIs of leading AI service providers, which has led to the emergence of companies like OpenRouter that broker the usage of different AI models from various providers for diverse business use cases.

    Teams need a reliable way to deliver applications and automation using many different public or private, open-source or commercial models. This use case provides the fundamentals for integrating across multiple AI model providers and immediately gaining more control over how small and large language models are being used as part of applications, automation, and direct integrations—optimizing cost, velocity, and risk across AI integrations.

  benefits:
    - Open-source implementation of model engine
    - On-premise implementation of model engine
    - Not limited to large language model domain
    - Capability routing over model or service routing
    - Business alignment with domain-driven consumption
    - Makes all APIs and data sources first-class citizens
    - Sovereign on-premise input and output controls
    - Standards-driven integrations with OpenAPI, etc.
    - FinOps Framework standardized price controls

  pain:

    - Bring AI Model Usage In-House (Ford, Cvent)
    - Unmanaged Usage
    - Unmanaged Spend
    - Unmanaged API Tokens
    - Unmanaged Encryption

  gains:  

    - Optimize Model Usage
    - Manage Budget Across
    - Managed Risk Involved
    - Create More Visibility

- name: Data Sovereignty
  description: |-
    This use case focuses on empowering companies to take control of their data that resides across the third-party SaaS solutions they use regularly. The data sovereignty movement is centered on establishing more control over the data generated across the different services you depend on, ensuring data is integrated, migrated, and synced to data and object stores where a company has full control and access.

    Data sovereignty enables teams to localize data and train local AI models using the data they produce across third-party platforms. This use case may be aligned with country or regional regulations, or it may simply be part of enterprise compliance programs. Data sovereignty investments have increased as part of the growth of AI integrations and the need for context across third-party systems, as well as the increasing value of data itself.

  benefits:
    - Aggregate 3rd-party SaaS data
    - Increase visibility of SaaS data
    - Allow for more SaaS data discovery
    - Encourage the reusability of SaaS data
    - Enable ETL/ELT access to SaaS data

  pain:

    - Regulatory Mandate for Data Sovereignty
    - Regulatory Mandate for Data Sovereignty
    - Unmanaged Discovery  

  gains: 

    - Aggregate 3rd-Party SaaS data
    - Create More Visibility
    - Create More Discovery
    - Create More Reusability 


- name: Capability Consumption
  description: |-
    This use case is designed to cover the general needs of the enterprise when it comes to integration with third-party SaaS. This use case allows for the widest possible definition of what is needed within a single domain, enabling exploration of which third-party services are required. This use case tends to focus specifically on the cost, velocity, and risk concerns of leadership, then identifying the services that are of particular concern.

    Teams need a way to centralize and standardize the usage and billing for third-party SaaS used as part of web, mobile, AI, or other types of applications. There is no consistent way to manage tokens, ensure encryption is used, and address other areas of concern when it comes to the risk across APIs. The capability consumption use case helps abstract away the general concerns of developers while providing the oversight leadership needs over different SaaS services.

  benefits:
    - Unlock access to legacy data
    - Right-size & unify APIs
    - Prepare foundation for AI future
    - Enterprise agility & composability

  pain: []

  gains: []    